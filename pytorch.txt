            Udacity Deep Learning Nano-Degree Notes 
1. Perceptrons
  perceptrons are representations of graphs, in a binary classification problem if we get a linear equation which can separate 
  the two classes then we can keep that function inside a node and the two inputs in two input nodes and the bias term also in
  a node ( in equation constant so thats why bias = 1 matrix multiplication)


 2. Brain Equivalent
 Dendrite - input 
 Nucleus - function
 Axon - output
 
 3. Perceptrons can be treated like logic gates which help us in solving mathematical problems
 
 4. Code for perceptron algorithm
             import numpy as np
             def stepFunction(t):
                if t >= 0:
                    return 1
                return 0

            def prediction(X, W, b):
                return stepFunction((np.matmul(X,W)+b)[0])
            def perceptronStep(X, y, W, b, learn_rate = 0.01):
                for i in range(len(X)):
                    y_hat = prediction(X[i],W,b)
                    if y[i]-y_hat == 1:
                        W[0] += X[i][0]*learn_rate
                        W[1] += X[i][1]*learn_rate
                        b += learn_rate
                    elif y[i]-y_hat == -1:
                        W[0] -= X[i][0]*learn_rate
                        W[1] -= X[i][1]*learn_rate
                        b -= learn_rate
                return W, b
            def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):
                x_min, x_max = min(X.T[0]), max(X.T[0])
                y_min, y_max = min(X.T[1]), max(X.T[1])
                W = np.array(np.random.rand(2,1))
                b = np.random.rand(1)[0] + x_max
                # These are the solution lines that get plotted below.
                boundary_lines = []
                for i in range(num_epochs):
                    # In each epoch, we apply the perceptron step.
                    W, b = perceptronStep(X, y, W, b, learn_rate)
                    boundary_lines.append((-W[0]/W[1], -b/W[1]))
                return boundary_lines
4. Gradient Descent problem
